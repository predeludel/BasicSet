{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Задание\n",
    "1. Выполнить предобработку текстов выбранного писателя. Инструментарий предобработки оформить в виде метода."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T22:13:02.001937100Z",
     "start_time": "2023-10-29T22:12:53.577855Z"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "nlp = spacy.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T22:13:05.175301900Z",
     "start_time": "2023-10-29T22:13:05.159030300Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "БарнебиРадж1841.txt\n",
      "ДомбиИсын1848.txt\n",
      "ЖизньИприключенияМартинаЧезлвита1844.txt\n",
      "КрошкаДоррит1857.txt\n",
      "ПриключенияОливераТвиста1839.txt\n",
      "ХолодныйДом1853.txt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "folder_path = r'D:\\workspace\\hw\\hw_task_majorIT\\NLP (Чавычалов)\\preprocessing'\n",
    "files = os.listdir(folder_path)\n",
    "txt_files = [f for f in files if f.endswith('.txt')]\n",
    "for file in txt_files:\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text_Book():\n",
    "    def __init__(self, name_book) -> None:\n",
    "        self.name_book = name_book\n",
    "        self.text = self.get_text()\n",
    "        self.words = self.get_words_text()\n",
    "        self.nlp = spacy.load('ru_core_news_sm')\n",
    "        self.doc = self.nlp(self.text)\n",
    "        self.lemm = nltk.WordNetLemmatizer()\n",
    "\n",
    "    def get_text(self):\n",
    "        with open(f'{self.name_book}.txt', 'r', encoding='utf-8') as f:\n",
    "            text = f.read()\n",
    "        tokens = word_tokenize(text)\n",
    "        return ' '.join(tokens) \n",
    "    \n",
    "    def get_words_text(self):\n",
    "        return nltk.tokenize.RegexpTokenizer(r\"\\w+\").tokenize(self.text)\n",
    "    \n",
    "    def get_lemma_words(self):\n",
    "        return [token.lemma_ for token in self.doc if not token.is_punct and not token.is_stop]\n",
    "    \n",
    "    def cosine_similarity(self, other):\n",
    "        words = set(self.get_lemma_words()).union(set(other.get_lemma_words()))\n",
    "        vec_1, vec_2 = np.array([self.get_lemma_words().count(word) for word in words]), np.array([other.get_lemma_words().count(word) for word in words])\n",
    "        return np.dot(vec_1, vec_2) / (np.linalg.norm(vec_1) * np.linalg.norm(vec_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T22:22:19.697429400Z",
     "start_time": "2023-10-29T22:13:08.569794100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83419 129922 170810 1320 189586 1229\n"
     ]
    }
   ],
   "source": [
    "words_1839 = Text_Book(\"ПриключенияОливераТвиста1839\").get_lemma_words()\n",
    "words_1841 = Text_Book(\"БарнебиРадж1841\").get_lemma_words()\n",
    "words_1844 = Text_Book(\"ЖизньИприключенияМартинаЧезлвита1844\").get_lemma_words()\n",
    "words_1848 = Text_Book(\"ДомбиИсын1848\").get_lemma_words()\n",
    "words_1853 = Text_Book(\"ХолодныйДом1853\").get_lemma_words()\n",
    "words_1857 = Text_Book(\"КрошкаДоррит1857\").get_lemma_words()\n",
    "print(len(words_1839), len(words_1841), len(words_1844), len(words_1848), len(words_1853), len(words_1857))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Задание\n",
    "2. Посчитать косинусное сходство текстов. Оформить также в виде метода. Допустимые библиотеки: numpy и sklearn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "Формула для косинусного расстояния:то чем более схожи векторы (объекты), тем меньше косинусное расстояние (поэтому оно иногда называется косинусная близость).\n",
    "\n",
    "![image.png](data:image/png;base64,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)\n",
    " \n",
    "Где dot(a, b) - скалярное произведение векторов, а norm - норма вектора, квадратный корень из суммы квадратов элементов вектора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-29T22:32:26.556301400Z",
     "start_time": "2023-10-29T22:27:34.669143500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7359517654362177 0.7692130792012323 0.6613829758816456 0.7432954375831234 0.5908507356704035\n"
     ]
    }
   ],
   "source": [
    "\n",
    "similarity_1839_vs_1841 = words_1839.cosine_similarity(words_1841)\n",
    "similarity_1839_vs_1844 = words_1839.cosine_similarity(words_1844)\n",
    "similarity_1839_vs_1848 = words_1839.cosine_similarity(words_1848)\n",
    "similarity_1839_vs_1853 = words_1839.cosine_similarity(words_1853)\n",
    "similarity_1839_vs_1857 = words_1839.cosine_similarity(words_1857)\n",
    "print(similarity_1839_vs_1841, similarity_1839_vs_1844,similarity_1839_vs_1848,similarity_1839_vs_1853,similarity_1839_vs_1857)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "По косинусному сходству текста Диккенса за 1839 к другим его текстам более поздних годов можно сделать вывод, что тексты имеют схожую структуру, используют похожие слова или имеют похожий смысл. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
